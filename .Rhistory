(plot_p_hack_classic / plot_p_hack_classic_prior) + plot_layout(guides = "collect") & theme(legend.position = "bottom")
(plot_p_hack_classic / plot_p_hack_classic_prior) +
plot_annotation(title = "Adjusted estimates assuming possible presence of p-hacking")
(plot_p_hack_classic / plot_p_hack_classic_prior) +
subtitle = "Estimates from Bayesian random effects main model and mixture model for p-hacking both with, and without, using prior (Hatzigeorgiadis et al., 2011)\nNote, models only include studies since 2011"
(plot_p_hack_classic / plot_p_hack_classic_prior) +
plot_annotation(title = "Adjusted estimates assuming possible presence of p-hacking",
subtitle = "Estimates from Bayesian random effects main model and mixture model for p-hacking both with, and without, using prior (Hatzigeorgiadis et al., 2011)\nNote, models only include studies since 2011")
(plot_p_hack_classic / plot_p_hack_classic_prior) +
plot_annotation(title = "Adjusted estimates assuming possible presence of p-hacking",
subtitle = "Estimates from Bayesian random effects main model and mixture model for p-hacking both with, and without, using prior (Hatzigeorgiadis et al., 2011)\nNote, models only include studies since 2011",
theme = theme(plot.title = element_text(size = 16))) +
plot_layout(guides = "collect") & theme(legend.position = "bottom")
(plot_p_hack_classic / plot_p_hack_classic_prior) +
plot_annotation(title = "Adjusted estimates assuming possible presence of p-hacking",
subtitle = "Estimates from Bayesian random effects main model and mixture model for p-hacking both with, and without, using prior (Hatzigeorgiadis et al., 2011)\nNote, models only include studies since 2011",
theme = theme(plot.subtitle = element_text(size = 8))) +
plot_layout(guides = "collect") & theme(legend.position = "bottom")
(plot_p_hack_classic / plot_p_hack_classic_prior) +
plot_annotation(title = "Adjusted estimates assuming possible presence of p-hacking",
subtitle = "Estimates from Bayesian random effects main model and mixture model for p-hacking both with, and without, using prior (Hatzigeorgiadis et al., 2011)\nNote, models only include studies since 2011 and ignore multilevel structure",
theme = theme(plot.subtitle = element_text(size = 8))) +
plot_layout(guides = "collect") & theme(legend.position = "bottom")
(plot_p_hack_classic / plot_p_hack_classic_prior) +
plot_annotation(title = "Adjusted estimates assuming possible presence of p-hacking",
subtitle = "Estimates from Bayesian random effects main model and mixture model for p-hacking both with, and without, using prior (Hatzigeorgiadis et al., 2011)\nNote, models ignore multilevel structure",
theme = theme(plot.subtitle = element_text(size = 8))) +
plot_layout(guides = "collect") & theme(legend.position = "bottom")
targets::tar_make(garbage_collection = TRUE)
targets::tar_make(garbage_collection = TRUE)
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_make()
library(publipha)
?phma()
targets::tar_load(data)
sample_sizes_st <- data %>%
select(group, n_st) %>%
group_by(group) %>%
summarise(n_st = max(n_st)) %>%
summarise(`All ST` = sum(n_st),
`Minumum ST` = min(n_st),
`Median ST` = median(n_st),
`Maximum ST` = max(n_st)
) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
library(patchwork)
library(tidyverse)
library(grid)
library(kableExtra)
targets::tar_load(data)
sample_sizes_st <- data %>%
select(group, n_st) %>%
group_by(group) %>%
summarise(n_st = max(n_st)) %>%
summarise(`All ST` = sum(n_st),
`Minumum ST` = min(n_st),
`Median ST` = median(n_st),
`Maximum ST` = max(n_st)
) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
targets::tar_load(data)
View(data)
sample_sizes_st <- data %>%
select(group_code, n_st) %>%
group_by(group_code) %>%
summarise(n_st = max(n_st)) %>%
summarise(`All ST` = sum(n_st),
`Minumum ST` = min(n_st),
`Median ST` = median(n_st),
`Maximum ST` = max(n_st)
) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
sample_sizes_con <- data %>%
select(study, n_con) %>%
group_by(study) %>%
summarise(n_con = max(n_con)) %>%
summarise(`All CON` = sum(n_con, na.rm =TRUE),
`Minumum CON` = min(n_con, na.rm =TRUE),
`Median CON` = median(n_con, na.rm =TRUE),
`Maximum CON` = max(n_con, na.rm =TRUE)) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
sample_sizes_con <- data %>%
select(study_code, n_con) %>%
group_by(study_code) %>%
summarise(n_con = max(n_con)) %>%
summarise(`All CON` = sum(n_con, na.rm =TRUE),
`Minumum CON` = min(n_con, na.rm =TRUE),
`Median CON` = median(n_con, na.rm =TRUE),
`Maximum CON` = max(n_con, na.rm =TRUE)) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
sample_sizes_st
sample_sizes_con
sample_sizes_st
sample_sizes_con
length(unique(data$study))
sample_sizes <- bind_rows(sample_sizes_st, sample_sizes_con)
sample_sizes
#| label: tbl-sample-sizes
#| tbl-cap-location: "top"
#| tbl-cap: Sample sizes for self-talk intervention and non-intervention control groups.
knitr::kable(
sample_sizes
) %>%
pack_rows("Self-talk", 1, 4) %>%
pack_rows("Control", 5, 8) %>%
footnote(general = c("ST = self-talk", "CON = non-intervention control")
) %>%
row_spec(0, bold = TRUE) %>%
kable_classic(full_width = FALSE)
length(unique(data$study_code))
#| label: fig-main-model
#| fig-width: 7.5
#| fig-height: 13.33
#| fig-cap: Panel (A) shows and ordered forest plot of study level effects. Panel (B) shows the prior and posterior distributions for the overall pooled estimates. Panel (C) shows log10(BF) calculated against each each point effect size from 0 to 1.
targets::tar_load(additional_study_sims_plot)
additional_study_sims_plot
targets::tar_load(tidy_pet_model)
targets::tar_load(tidy_rma.mv_model)
targets::tar_load(null_robma_model)
targets::tar_load(prior_robma_model)
targets::tar_load(p_hack_model)
targets::tar_load(classic_model)
targets::tar_load(p_hack_model_prior)
targets::tar_load(classic_model_prior)
targets::tar_load(tidy_pet_model)
targets::tar_load(tidy_rma.mv_model)
targets::tar_load(null_robma_model)
targets::tar_load(prior_robma_model)
targets::tar_load(p_hack_model)
targets::tar_load(classic_model)
targets::tar_load(p_hack_model_prior)
targets::tar_load(classic_model_prior)
targets::tar_load(main_model_contour_funnel_plot)
targets::tar_load(p_hack_models_plots)
main_model_contour_funnel_plot
p_hack_models_plots
tidy_pet_model
lochbaum <- c(0.57,1.35,0.65,0.32,0.24,0.51,0.51,0.48,0.72,1,0.22,0.49,0.48,0.47,0.68,0.28,0.2,0.44,0.32,0.34,0.84,0.38,0.38,0.38,0.74,0.72,0.82,0.72,0.15,0.47,0.31,0.49,0.49,0.65)
# Prediction interval
targets::tar_load(main_model)
nd <- data.frame(study = "new", vi = 0)
pred_int_data <- brms::posterior_predict(
object = main_model,
newdata = nd,
re_formula = NULL,
allow_new_levels = TRUE,
sample_new_levels = "gaussian"
)
pred_int_data <- tidybayes::median_qi(pred_int_data) %>%
mutate(label = as.character("Posterior Pooled Estimate"))
min(lochbaum)
max(lochbaum)
pred_int_data
#| label: fig-contour-plot
#| fig-width: 5
#| fig-height: 5
#| fig-cap: Countour enhanced funnel plot showing effect sizes (scaled in size by inverse sampling variance), thresholds for *p* < 0.05 and 0.01, and both PET-PEESE estimate (in this case it is the PET estimate from the conditional estimator; regression line and ribbon plus "Multilevel PET Estimate" labelled point and interval) and frequentist multilevel model estimate ("Main Model Estimate" labelled point and interval).
targets::tar_load(main_model_contour_funnel_plot)
main_model_contour_funnel_plot
tidy_rma.mv_model
round(tidy_rma.mv_model$estimate[1],2)
tidy_pet_model
p_hack_model
broom.mixed::tidy(p_hack_model)
broom.mixed::tidy(p_hack_model, conf.int = .95)
broom.mixed::tidy(prior_robma_model, conf.int = .95)
targets::tar_make()
_hack_model)
targets::tar_load(tidy_p_hack_model)
targets::tar_load(tidy_classic_model)
targets::tar_load(tidy_p_hack_model_prior)
targets::tar_load(tidy_classic_model_prior)
tidy_classic_model
tidy_classic_model$estimate[1]
tidy_classic_model$conf.low[1]
RoBMA::interpret(null_robma_model)
RoBMA::interpret(prior_robma_model)
View(prior_robma_model)
RoBMA::forest(prior_robma_model)
summary(prior_robma_model)
sum <- summary(prior_robma_model)
sum$components
sum$components$inclusion_BF[2]
summary(null_robma_model)$components$inclusion_BF[2]
round(summary(null_robma_model)$components$inclusion_BF[2],3)
round(as.numeric(summary(null_robma_model)$components$inclusion_BF[2]),3)
round(summary(null_robma_model)$components$inclusion_BF[1],3)
round(5.872685e+16)
sum$estimates
sum$estimates$Mean[1]
sum$estimates$0.025
sum$estimates$`0.025`
summary(null_robma_model)$estimates[1]
summary(null_robma_model)$estimates[1,1]
summary(null_robma_model)$estimates[1,2]
summary(null_robma_model)$estimates[2,1]
round(summary(null_robma_model)$estimates[1,1],2)
sum$estimates$Mean
sum$estimates
as.data.frame(sum$estimates)
RoBMA::diagnostics(null_robma_model)
RoBMA::diagnostics(null_robma_model,
parameter = "mu")
RoBMA::diagnostics(null_robma_model,
parameter = "mu",
type = "chains")
RoBMA::diagnostics(prior_robma_model,
parameter = "mu",
type = "chains")
RoBMA::diagnostics(null_robma_model,
parameter = c("mu", "tau"),
type = "chains")
robma_plots <-  RoBMA::diagnostics(null_robma_model,
parameter = "mu",
type = "chains")
View(robma_plots)
RoBMA::summary(prior_robma_model)
RoBMA::summary.RoBMA(prior_robma_model)
RoBMA::check_RoBMA(prior_robma_model)
RoBMA::check_RoBMA(null_robma_model)
RoBMA::summary(null_robma_model, type = "models")
RoBMA::summary.RoBMA(null_robma_model, type = "models")
summary.RoBMA(null_robma_model, type = "models")
summary(null_robma_model, type = "models")
RoBMA::diagnostics(null_robma_model,
parameter = "mu",
type = "chains")
rstan::check_hmc_diagnostics(p_hack_model)
null_robma_model
summary(null_robma_model)
targets::tar_visnetwork()
targets::tar_visnetwork()
install.packages("quarto")
targets::tar_visnetwork()
targets::tar_make()
targets::tar_make()
install.packages("grateful")
targets::tar_make()
round(summary(null_robma_model)$components$inclusion_BF[1]
round(summary(null_robma_model)$components$inclusion_BF[1],2)
sum_null_robma_model <- summary(null_robma_model)
sum_prior_robma_model <- summary(prior_robma_model)
targets::tar_make()
lochbaum <- c(0.57,1.35,0.65,0.32,0.24,0.51,0.51,0.48,0.72,1,0.22,0.49,0.48,0.47,0.68,0.28,0.2,0.44,0.32,0.34,0.84,0.38,0.38,0.38,0.74,0.72,0.82,0.72,0.15,0.47,0.31,0.49,0.49,0.65)
# Prediction interval
targets::tar_load(main_model)
nd <- data.frame(study = "new", vi = 0)
pred_int_data <- brms::posterior_predict(
object = main_model,
newdata = nd,
re_formula = NULL,
allow_new_levels = TRUE,
sample_new_levels = "gaussian"
)
pred_int_data <- tidybayes::median_qi(pred_int_data) %>%
mutate(label = as.character("Posterior Pooled Estimate"))
round(tidy_main_model$estimate[2],2)
targets::tar_load(tidy_main_model)
round(tidy_main_model$estimate[2],2)
round(pred_int_data$ymax,2)
round(tidy_main_model$conf.low[2],2)
round(tidy_main_model$conf.high[2],2)
View(tidy_main_model)
round(pred_int_data$ymin,2)
round(pred_int_data$ymax,2)
pred_int_data
lochbaum
nd
pred_int_data
pred_int_data$ymin
View(tidy_main_model)
tidy_main_model
min(lochbaum)
max(lochbaum)
tidy_main_model$conf.low[2]
round(tidy_main_model$conf.low[2],2)
round(tidy_main_model$conf.low[2],2)
round(tidy_main_model$estimate[2],2)
round(tidy_main_model$conf.high[2],2)
round(pred_int_data$ymin,2)
r round(pred_int_data$ymax,2)
round(pred_int_data$ymax,2)
#| label: fig-main-model
#| fig-width: 7.5
#| fig-height: 13.33
#| fig-cap: Panel (A) shows and ordered forest plot of study level effects. Panel (B) shows the prior and posterior distributions for the overall pooled estimates. Panel (C) shows log10(BF) calculated against each each point effect size from 0 to 1.
targets::tar_load(main_model_forest_plot)
targets::tar_load(main_model_update_plot)
round(tidy_main_model$estimate[1],2)
round(tidy_main_model$conf.low[1],2)
round(tidy_main_model$conf.high[1],2)
round(Jeffreys_scales$min_effect[9],2)
main_model_logBF_curve <-  main_model_logBF_curve %>%
mutate(log10BF = log10(exp(BF.log_BF)))
targets::tar_load(main_model)
targets::tar_load(tidy_main_model)
targets::tar_load(main_model_logBF_curve)
main_model_logBF_curve <-  main_model_logBF_curve %>%
mutate(log10BF = log10(exp(BF.log_BF)))
log10BF_loess <- loess(log10BF ~ effect,
data = main_model_logBF_curve)
Jeffreys_scales <- main_model_logBF_curve %>%
mutate(log10BF_pred = predict(log10BF_loess)) %>%
mutate(Jeffreys_scale = case_when(
log10BF_pred <= 0.5 ~ "Weak",
log10BF_pred <= 1 ~ "Substantial",
log10BF_pred <= 1.5 ~ "Strong",
log10BF_pred <= 2.0 ~ "Very Strong",
log10BF_pred > 2.0  ~ "Decisive"
)) %>%
mutate(log10BF_diff = log10BF_pred - lag(log10BF_pred, default = log10BF_pred[1]),
sign = case_when(
log10BF_diff < 0 ~ "Negative",
log10BF_diff >= 0 ~ "Positive"
)) %>%
slice(2:100) %>%
group_by(Jeffreys_scale, sign) %>%
select(Jeffreys_scale, sign, effect) %>%
summarise(min_effect = min(effect),
max_effect = max(effect))
Jeffreys_scales
round(Jeffreys_scales$min_effect[9],2)
round(Jeffreys_scales$max_effect[10],2)
round(Jeffreys_scales$max_effect[1],2)
round(Jeffreys_scales$min_effect[2],2)
round(Jeffreys_scales$max_effect[2],2)
length(unique(data$study))
pred_int_data <- tidybayes::median_qi(pred_int_data)
pred_int_data
lochbaum
pred_int_data
pred_int_data$ymin[1]
pred_int_data$ymin
tidy_main_model$conf.low[2
tidy_main_model$conf.low[2]
tidy_main_model$conf.low[2]
round(tidy_main_model$conf.low[2],2)
tidy_main_model
tidy_main_model |>
row.names()
tidy_main_model |>
names()
round(as.numeric(tidy_main_model$estimate[2],2))
round(as.numeric(tidy_main_model$conf.low[2],2))
as.numeric(tidy_main_model$estimate[2],2)
as.numeric(tidy_main_model$conf.low[2]
round(as.numeric(tidy_main_model$estimate[2]),2)
as.numeric(tidy_main_model$estimate[2])
round(as.numeric(tidy_main_model$estimate[2]),2)
lochbaum <- c(0.57,1.35,0.65,0.32,0.24,0.51,0.51,0.48,0.72,1,0.22,0.49,0.48,0.47,0.68,0.28,0.2,0.44,0.32,0.34,0.84,0.38,0.38,0.38,0.74,0.72,0.82,0.72,0.15,0.47,0.31,0.49,0.49,0.65)
nd <- data.frame(study = "new", vi = 0)
pred_int_data <- brms::posterior_predict(
object = main_model,
newdata = nd,
re_formula = NULL,
allow_new_levels = TRUE,
sample_new_levels = "gaussian"
)
pred_int_data <- tidybayes::qi(pred_int_data)
lochbaum <- c(0.57,1.35,0.65,0.32,0.24,0.51,0.51,0.48,0.72,1,0.22,0.49,0.48,0.47,0.68,0.28,0.2,0.44,0.32,0.34,0.84,0.38,0.38,0.38,0.74,0.72,0.82,0.72,0.15,0.47,0.31,0.49,0.49,0.65)
nd <- data.frame(study = "new", vi = 0)
pred_int_data <- brms::posterior_predict(
object = main_model,
newdata = nd,
re_formula = NULL,
allow_new_levels = TRUE,
sample_new_levels = "gaussian"
)
pred_int_summary <- tidybayes::qi(pred_int_data)
pred_int_summary
pred_int_summary[2]
round(pred_int_summary[1],2)
#| label: fig-phack-plot
#| fig-width: 5
#| fig-height: 5
#| fig-cap: Posterior distributions for Bayesian random effects main model (classic model) and mixture model for *p*-hacking both with and without using the prior from Hatzigeorgiadis et al. [-@hatzigeorgiadisSelfTalkSportsPerformance2011].
targets::tar_load(p_hack_models_plot)
targets::tar_load(p_hack_models_prior_plot)
(p_hack_models_plot / p_hack_models_prior_plot) +
plot_annotation(title = "Adjusted estimates assuming possible presence of p-hacking",
subtitle = "Estimates from Bayesian random effects main model and mixture model for p-hacking both with, and without, using prior\nNote, models ignore multilevel structure",
theme = theme(plot.subtitle = element_text(size = 8))) +
plot_layout(guides = "collect") & theme(legend.position = "bottom")
#| label: fig-contour-plot
#| fig-width: 5
#| fig-height: 5
#| fig-cap: Countour enhanced funnel plot showing effect sizes (scaled in size by inverse sampling variance), thresholds for *p* < 0.05 and 0.01, and both PET-PEESE estimate (in this case it is the PET estimate from the conditional estimator; regression line and ribbon plus "Multilevel PET Estimate" labelled point and interval) and frequentist multilevel model estimate ("Main Model Estimate" labelled point and interval).
targets::tar_load(main_model_contour_funnel_plot)
main_model_contour_funnel_plot
R.version
R.Version()
R.version()$version.string
R.version()
R.Version()$version.string
targets::tar_make()
install.packages("quarto")
renv::status()
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_load(tidy_pet_model)
#| label: fig-moderators-models
#| fig-width: 21
#| fig-height: 12
#| fig-cap: Prior and posterior distributions for each moderator explored; Panel (A) motor demands, (B) participant population, (C) self-talk content, (D) matching hypothesis, (E) task novelty, (F) cue selection, (G) overtness selection, (H) training intervention or not, and (I) study design.
targets::tar_load(motor_demands_model_plot)
targets::tar_make()
#| label: fig-moderators-models
#| fig-width: 21
#| fig-height: 12
#| fig-cap: Prior and posterior distributions for each moderator explored; Panel (A) motor demands, (B) participant population, (C) self-talk content, (D) matching hypothesis, (E) task novelty, (F) cue selection, (G) overtness selection, (H) training intervention or not, and (I) study design.
targets::tar_load(motor_demands_model_plot)
targets::tar_load(tidy_pet_model)
targets::tar_make()
sum_null_robma_model <- as.data.frame(summary(null_robma_model))
targets::tar_load(tidy_pet_model)
targets::tar_load(tidy_rma.mv_model)
targets::tar_load(null_robma_model)
targets::tar_load(prior_robma_model)
targets::tar_load(tidy_p_hack_model)
targets::tar_load(tidy_classic_model)
targets::tar_load(tidy_p_hack_model_prior)
targets::tar_load(tidy_classic_model_prior)
targets::tar_load(p_hack_models_plots)
sum_null_robma_model <- as.data.frame(summary(null_robma_model))
sum_prior_robma_model <-  as.data.frame(summary(prior_robma_model))
round(sum_null_robma_model$components$inclusion_BF[1],3)
summary(prior_robma_model)
summary(null_robma_model)
summary(null_robma_model)
View(sum_null_robma_model)
sum_null_robma_model <- summary(null_robma_model)
sum_null_robma_model <- summary(null_robma_model)
summary(null_robma_model)
null_robma_model
null_robma_model
library(RoBMA)
summary(null_robma_model)
sum_null_robma_model <- summary(null_robma_model)
round(sum_null_robma_model$components$inclusion_BF[1],3)
targets::tar_make()
round(sum_prior_robma_model$estimates[2,3],2)
library(RoBMA)
sum_null_robma_model <- summary(null_robma_model)
sum_prior_robma_model <-  summary(prior_robma_model)
round(sum_prior_robma_model$estimates[2,3],2)
sum_null_robma_model
targets::tar_make()
targets::tar_make()
round(sum_null_robma_model$components$inclusion_BF[1],3)
targets::tar_make()
targets::tar_make()
grateful::cite_packages(output = "paragraph", cite.tidyverse = TRUE, out.dir = ".")
length(unique(data$study))
targets::tar_load(data)
sample_sizes_st <- data %>%
select(group_code, n_st) %>%
group_by(group_code) %>%
summarise(n_st = max(n_st)) %>%
summarise(`All ST` = sum(n_st),
`Minumum ST` = min(n_st),
`Median ST` = median(n_st),
`Maximum ST` = max(n_st)
) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
library(tidyverse)
targets::tar_load(data)
sample_sizes_st <- data %>%
select(group_code, n_st) %>%
group_by(group_code) %>%
summarise(n_st = max(n_st)) %>%
summarise(`All ST` = sum(n_st),
`Minumum ST` = min(n_st),
`Median ST` = median(n_st),
`Maximum ST` = max(n_st)
) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
sample_sizes_con <- data %>%
select(study_code, n_con) %>%
group_by(study_code) %>%
summarise(n_con = max(n_con)) %>%
summarise(`All CON` = sum(n_con, na.rm =TRUE),
`Minumum CON` = min(n_con, na.rm =TRUE),
`Median CON` = median(n_con, na.rm =TRUE),
`Maximum CON` = max(n_con, na.rm =TRUE)) %>%
pivot_longer(1:4, names_to = "Group", values_to = "Sample Size")
sample_sizes <- bind_rows(sample_sizes_st, sample_sizes_con)
length(unique(data$study_code))
length(unique(data$study))
length(unique(data$study_code))
targets::tar_make()
targets::tar_make()
grateful::cite_packages(out.dir = ".pre_print", cite.tidyverse = TRUE, out.format = "pdf")
grateful::cite_packages(out.dir = "pre_print", cite.tidyverse = TRUE, out.format = "pdf")
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_visnetwork()
targets::tar_make()
targets::tar_make()
gratefull::cite_packages(out.dir = "pre_print", cite.tidyverse = TRUE, out.format = "pdf", include.RStudio = TRUE)
grateful::cite_packages(out.dir = "pre_print", cite.tidyverse = TRUE, out.format = "pdf", include.RStudio = TRUE)
targets::tar_make()
targets::tar_make()
targets::tar_make()
targets::tar_make()
install.packages("funchir")
funchir::stale_package_check()
targets::tar_make()
