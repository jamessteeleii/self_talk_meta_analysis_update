spread_draws(b_Intercept) %>%
mutate(year = "Hatzigeorgiadis et al., (2011)") %>%
select(year, b_Intercept)
prior_draws <-
prior_main_model %>%
spread_draws(b_Intercept) %>%
mutate(year = "Hatzigeorgiadis et al., (2011)") %>%
select(year, b_Intercept)
rbind(prior_draws, cumulative_draws)
cumulative_draws <- rbind(prior_draws, cumulative_draws) %>%
mutate(year = factor(year, levels = c(
"Hatzigeorgiadis et al., (2011)",
"2011",
"2012",
"2013",
"2014",
"2015",
"2016",
"2017",
"2018",
"2019",
"2020",
"2021",
"2022"
)))
cumulative_draws %>%
ggplot(aes(y = year, x = b_Intercept)) +
# Add ref line at zero
geom_vline(xintercept = 0, linetype = 2) +
# Add densities and point intervals
geom_density_ridges(
fill = "darkgrey",
rel_min_height = 0.01,
scale = 1,
alpha = 0.8
) +
stat_pointinterval(point_interval = mean_qi,
.width = .95,
size = 1) +
# Add individual study data subset(Data_effects, !is.na(yi)), aes(x = yi, y = study_name)
geom_point(
data = subset(data,!is.na(yi)),
aes(x = yi, y = as.factor(year)),
position = position_nudge(y = -0.1),
shape = "|"
) +
# Add labs and theme
labs(y = "Year",
x = "Standardised Mean Difference (Positive Values Favour Self-Talk)",
title = "Cumulative Updating of Posterior Pooled Estimate",
subtitle = "Each year uses the previous years posterior pooled estimate as its prior\nPosterior distributions, mean and 95% quantile intervals, and individual effects (ticks)") +
# scale_y_continuous(limits = c(-0.5, 1), breaks = c(-0.5, 0, 0.5, 1)) +
scale_y_discrete(limits = rev,
labels = function(x) str_wrap(x, width = 15)) +
theme_classic() +
theme(panel.border = element_rect(fill = NA),
plot.subtitle = element_text(size=6))
targets::tar_make()
targets::tar_make()
View(prior_draws)
prior_draws <-
prior_main_model %>%
spread_draws(b_Intercept) %>%
mutate(year = "Hatzigeorgiadis et al., (2011)")
View(prior_draws)
targets::tar_make()
targets::tar_load(cumulative_draws)
View(cumulative_draws)
targets::tar_load(prior_main_model)
prior_main_model %>%
spread_draws(b_Intercept) %>%
mutate(year = "Hatzigeorgiadis et al., (2011)") %>%
select(year, b_Intercept)
prior_draws <- prior_main_model %>%
spread_draws(b_Intercept) %>%
mutate(year = "Hatzigeorgiadis et al., (2011)") %>%
select(year, b_Intercept)
cumulative_draws <- rbind(prior_draws, cumulative_draws) %>%
mutate(year = factor(year, levels = c(
"Hatzigeorgiadis et al., (2011)",
"2011",
"2012",
"2013",
"2014",
"2015",
"2016",
"2017",
"2018",
"2019",
"2020",
"2021",
"2022"
)))
cumulative_draws %>%
ggplot(aes(y = year, x = b_Intercept)) +
# Add ref line at zero
geom_vline(xintercept = 0, linetype = 2) +
# Add densities and point intervals
geom_density_ridges(
fill = "darkgrey",
rel_min_height = 0.01,
scale = 1,
alpha = 0.8
) +
stat_pointinterval(point_interval = mean_qi,
.width = .95,
size = 1) +
# Add individual study data subset(Data_effects, !is.na(yi)), aes(x = yi, y = study_name)
geom_point(
data = subset(data,!is.na(yi)),
aes(x = yi, y = as.factor(year)),
position = position_nudge(y = -0.1),
shape = "|"
) +
# Add labs and theme
labs(y = "Year",
x = "Standardised Mean Difference (Positive Values Favour Self-Talk)",
title = "Cumulative Updating of Posterior Pooled Estimate",
subtitle = "Each year uses the previous years posterior pooled estimate as its prior\nPosterior distributions, mean and 95% quantile intervals, and individual effects (ticks)") +
# scale_y_continuous(limits = c(-0.5, 1), breaks = c(-0.5, 0, 0.5, 1)) +
scale_y_discrete(limits = rev,
labels = function(x) str_wrap(x, width = 15)) +
theme_classic() +
theme(panel.border = element_rect(fill = NA),
plot.subtitle = element_text(size=6))
targets::tar_make()
?select
targets::tar_make()
targets::tar_make()
targets::tar_make()
posterior_summary <- group_by(cumulative_draws, year) %>%
mean_qi(b_Intercept)
cumulative_draws %>%
ggplot(aes(y = year, x = b_Intercept)) +
# Add ref line at zero
geom_vline(xintercept = 0, linetype = 2) +
# Add densities and point intervals
geom_density_ridges(
fill = "darkgrey",
rel_min_height = 0.01,
scale = 1,
alpha = 0.8
) +
stat_pointinterval(point_interval = mean_qi,
.width = .95,
size = 1) +
# Add individual study data subset(Data_effects, !is.na(yi)), aes(x = yi, y = study_name)
geom_point(
data = subset(data,!is.na(yi)),
aes(x = yi, y = as.factor(year)),
position = position_nudge(y = -0.1),
shape = "|"
) +
# Add text and labels
geom_text(
data = mutate_if(posterior_summary,
is.numeric, round, 2),
aes(
label = glue::glue("{b_Intercept} [{.lower}, {.upper}]"),
x = 4
),
hjust = "inward",
size = 3
) +
# Add labs and theme
labs(y = "Year",
x = "Standardised Mean Difference (Positive Values Favour Self-Talk)",
title = "Cumulative Updating of Posterior Pooled Estimate",
subtitle = "Each year uses the previous years posterior pooled estimate as its prior\nPosterior distributions, mean and 95% quantile intervals, and individual effects (ticks)") +
# scale_y_continuous(limits = c(-0.5, 1), breaks = c(-0.5, 0, 0.5, 1)) +
scale_y_discrete(limits = rev,
labels = function(x) str_wrap(x, width = 15)) +
theme_classic() +
theme(panel.border = element_rect(fill = NA),
plot.subtitle = element_text(size=6))
cumulative_draws %>%
ggplot(aes(y = year, x = b_Intercept)) +
# Add ref line at zero
geom_vline(xintercept = 0, linetype = 2) +
# Add densities and point intervals
geom_density_ridges(
fill = "darkgrey",
rel_min_height = 0.01,
scale = 1,
alpha = 0.8
) +
stat_pointinterval(point_interval = mean_qi,
.width = .95,
size = 1) +
# Add individual study data subset(Data_effects, !is.na(yi)), aes(x = yi, y = study_name)
# geom_point(
#   data = subset(data,!is.na(yi)),
#   aes(x = yi, y = as.factor(year)),
#   position = position_nudge(y = -0.1),
#   shape = "|"
# ) +
# Add text and labels
geom_text(
data = mutate_if(posterior_summary,
is.numeric, round, 2),
aes(
label = glue::glue("{b_Intercept} [{.lower}, {.upper}]"),
x = 4
),
hjust = "inward",
size = 3
) +
# Add labs and theme
labs(y = "Year",
x = "Standardised Mean Difference (Positive Values Favour Self-Talk)",
title = "Cumulative Updating of Posterior Pooled Estimate",
subtitle = "Each year uses the previous years posterior pooled estimate as its prior\nPosterior distributions, mean and 95% quantile intervals, and individual effects (ticks)") +
# scale_y_continuous(limits = c(-0.5, 1), breaks = c(-0.5, 0, 0.5, 1)) +
scale_y_discrete(limits = rev,
labels = function(x) str_wrap(x, width = 15)) +
theme_classic() +
theme(panel.border = element_rect(fill = NA),
plot.subtitle = element_text(size=6))
targets::tar_make()
targets::tar_load(cumulative_main_model_plot)
cumulative_main_model_plot +
transition_states(year,
transition_length = 2,
state_length = 1)
targets::tar_visnetwork()
targets::tar_visnetwork()
targets::tar_make()
targets::tar_load(cumulative_draws)
View(cumulative_draws)
unique(cumulative_draws$prior)
targets::tar_load(cumulative_main_model_plot)
targets::tar_load(cumulative_main_model_plot)
cumulative_main_model_plot +
transition_states(
year,
transition_length = 2,
state_length = 1
)
library(tidyverse)
library(gganimate)
cumulative_main_model_plot +
transition_states(
year,
transition_length = 2,
state_length = 1
)
cumulative_main_model_plot +
transition_reveal(
year
)
cumulative_main_model_plot +
transition_states(
year
)
cumulative_main_model_plot +
transition_reveal(
as.numeric(year)
)
anim_save(path = "plot/cumulative_plot.gif")
anim_save("cumulative_plot.gif", path = "plot/cumulative_plot.gif")
anim_save("cumulative_plot.gif", path = "plot")
anim_save("cumulative_plot.gif")
cumulative_main_model_plot +
transition_reveal(
as.numeric(year)
)
cumulative_main_model_plot +
transition_reveal(
as.numeric(year)
)
cumulative_main_model_plot
targets::tar_visnetwork()
targets::tar_make_future(workers = 3)
targets::tar_make()
targets::tar_visnetwork()
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(pre_se_st * sqrt(n_st)),
pre_sd_con = replace_na(pre_se_con * sqrt(n_con)),
post_sd_st = replace_na(post_se_st * sqrt(n_st)),
post_sd_con = replace_na(post_se_con * sqrt(n_con))
)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
# clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(pre_se_st * sqrt(n_st)),
pre_sd_con = replace_na(pre_se_con * sqrt(n_con)),
post_sd_st = replace_na(post_se_st * sqrt(n_st)),
post_sd_con = replace_na(post_se_con * sqrt(n_con))
)
library(janitor)
library(here)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(pre_se_st * sqrt(n_st)),
pre_sd_con = replace_na(pre_se_con * sqrt(n_con)),
post_sd_st = replace_na(post_se_st * sqrt(n_st)),
post_sd_con = replace_na(post_se_con * sqrt(n_con))
)
View(data)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(if_else(is.na(pre_sd_st),
pre_se_st * sqrt(n_st)), pre_sd_st),
pre_sd_con = replace_na(if_else(is.na(pre_sd_con),
pre_se_con * sqrt(n_con)), pre_sd_con),
post_sd_st = replace_na(if_else(is.na(post_sd_st),
post_se_st * sqrt(n_st)), post_sd_st),
post_sd_con = replace_na(if_else(is.na(post_sd_con),
post_se_con * sqrt(n_con)), post_sd_con)
)
View(data)
targets::tar_visnetwork()
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(if_else(is.na(pre_sd_st),
pre_se_st * sqrt(n_st)), pre_sd_st),
pre_sd_con = replace_na(if_else(is.na(pre_sd_con),
pre_se_con * sqrt(n_con)), pre_sd_con),
post_sd_st = replace_na(if_else(is.na(post_sd_st),
post_se_st * sqrt(n_st)), post_sd_st),
post_sd_con = replace_na(if_else(is.na(post_sd_con),
post_se_con * sqrt(n_con)), post_sd_con)
) %>%
# Add in pre-post correlations
mutate(
# Convert p to t (Change scores)
delta_t_value_st = replace_na(qt(delta_p_value_st/2, df=n_st-1, lower.tail=FALSE)),
delta_t_value_con = replace_na(qt(delta_p_value_con/2, df=n_con-1, lower.tail=FALSE)),
# Convert t to SE (Change scores)
delta_se_st = replace_na(if_else(is.na(delta_m_st),
(post_m_st - pre_m_st)/delta_t_value_st, delta_m_st/delta_t_value_st)),
delta_se_con = replace_na(if_else(is.na(delta_m_con),
(post_m_con - pre_m_con)/delta_t_value_con, delta_m_con/delta_t_value_con)),
# Make positive
delta_se_st = if_else(delta_se_st < 0, delta_se_st * -1, delta_se_st),
delta_se_con = if_else(delta_se_con < 0, delta_se_con * -1, delta_se_con),
# Convert SE to SD (Change scores)
delta_sd_st = replace_na(if_else(is.na(delta_sd_st),
delta_se_st * sqrt(n_st)), delta_sd_st),
delta_sd_con = replace_na(if_else(is.na(delta_sd_con),
delta_se_con * sqrt(n_con)), delta_sd_con),
# Add missing deltas
delta_m_st = replace_na(post_m_st - pre_m_st),
delta_m_con = replace_na(post_m_con - pre_m_con),
# Calculate pre-post correlation coefficient for those with pre, post, and delta SDs
ri_st = replace_na((pre_sd_st^2 + post_sd_st^2 - delta_sd_st^2)/(2 * pre_sd_st * post_sd_st)),
ri_con = replace_na((pre_sd_con^2 + post_sd_con^2 - delta_sd_con^2)/(2 * pre_sd_con * post_sd_con)),
# Remove values outside the range of -1 to +1 as they are likely due to misreporting or miscalculations in original studies
ri_st = if_else(between(ri_st,-1,1) == FALSE, NA, ri_st),
ri_con = if_else(between(ri_con,-1,1) == FALSE, NA, ri_con),
# Add 0.7 assumed correlation where missing
ri_st = replace_na(ri_st, 0.7),
ri_con = replace_na(ri_con, 0.7)
)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(if_else(is.na(pre_sd_st),
pre_se_st * sqrt(n_st), pre_sd_st)),
pre_sd_con = replace_na(if_else(is.na(pre_sd_con),
pre_se_con * sqrt(n_con), pre_sd_con)),
post_sd_st = replace_na(if_else(is.na(post_sd_st),
post_se_st * sqrt(n_st), post_sd_st)),
post_sd_con = replace_na(if_else(is.na(post_sd_con),
post_se_con * sqrt(n_con), post_sd_con))
)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(if_else(is.na(pre_sd_st),
pre_se_st * sqrt(n_st), pre_sd_st)),
pre_sd_con = replace_na(if_else(is.na(pre_sd_con),
pre_se_con * sqrt(n_con), pre_sd_con)),
post_sd_st = replace_na(if_else(is.na(post_sd_st),
post_se_st * sqrt(n_st), post_sd_st)),
post_sd_con = replace_na(if_else(is.na(post_sd_con),
post_se_con * sqrt(n_con), post_sd_con))
)
View(data)
targets::tar_make_future(workers = 4)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(if_else(is.na(pre_sd_st),
pre_se_st * sqrt(n_st), pre_sd_st)),
pre_sd_con = replace_na(if_else(is.na(pre_sd_con),
pre_se_con * sqrt(n_con), pre_sd_con)),
post_sd_st = replace_na(if_else(is.na(post_sd_st),
post_se_st * sqrt(n_st), post_sd_st)),
post_sd_con = replace_na(if_else(is.na(post_sd_con),
post_se_con * sqrt(n_con), post_sd_con))
)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(if_else(is.na(pre_sd_st),
pre_se_st * sqrt(n_st), pre_sd_st)),
pre_sd_con = replace_na(if_else(is.na(pre_sd_con),
pre_se_con * sqrt(n_con), pre_sd_con)),
post_sd_st = replace_na(if_else(is.na(post_sd_st),
post_se_st * sqrt(n_st), post_sd_st)),
post_sd_con = replace_na(if_else(is.na(post_sd_con),
post_se_con * sqrt(n_con), post_sd_con))
) %>%
# Add in pre-post correlations
mutate(
# Convert p to t (Change scores)
delta_t_value_st = replace_na(qt(delta_p_value_st/2, df=n_st-1, lower.tail=FALSE)),
delta_t_value_con = replace_na(qt(delta_p_value_con/2, df=n_con-1, lower.tail=FALSE)),
# Convert t to SE (Change scores)
delta_se_st = replace_na(if_else(is.na(delta_m_st),
(post_m_st - pre_m_st)/delta_t_value_st, delta_m_st/delta_t_value_st)),
delta_se_con = replace_na(if_else(is.na(delta_m_con),
(post_m_con - pre_m_con)/delta_t_value_con, delta_m_con/delta_t_value_con)),
# Make positive
delta_se_st = if_else(delta_se_st < 0, delta_se_st * -1, delta_se_st),
delta_se_con = if_else(delta_se_con < 0, delta_se_con * -1, delta_se_con),
# Convert SE to SD (Change scores)
delta_sd_st = replace_na(if_else(is.na(delta_sd_st),
delta_se_st * sqrt(n_st)), delta_sd_st),
delta_sd_con = replace_na(if_else(is.na(delta_sd_con),
delta_se_con * sqrt(n_con)), delta_sd_con),
# Add missing deltas
delta_m_st = replace_na(post_m_st - pre_m_st),
delta_m_con = replace_na(post_m_con - pre_m_con),
# Calculate pre-post correlation coefficient for those with pre, post, and delta SDs
ri_st = replace_na((pre_sd_st^2 + post_sd_st^2 - delta_sd_st^2)/(2 * pre_sd_st * post_sd_st)),
ri_con = replace_na((pre_sd_con^2 + post_sd_con^2 - delta_sd_con^2)/(2 * pre_sd_con * post_sd_con)),
# Remove values outside the range of -1 to +1 as they are likely due to misreporting or miscalculations in original studies
ri_st = if_else(between(ri_st,-1,1) == FALSE, NA, ri_st),
ri_con = if_else(between(ri_con,-1,1) == FALSE, NA, ri_con),
# Add 0.7 assumed correlation where missing
ri_st = replace_na(ri_st, 0.7),
ri_con = replace_na(ri_con, 0.7)
)
data <- read_csv(here("data", "Final data.csv")) %>%
mutate_at(c(2:9, 41:43, 45:48), as.factor) %>%
clean_names() %>%
# Convert SE to SD
mutate(
pre_sd_st = replace_na(if_else(is.na(pre_sd_st),
pre_se_st * sqrt(n_st), pre_sd_st)),
pre_sd_con = replace_na(if_else(is.na(pre_sd_con),
pre_se_con * sqrt(n_con), pre_sd_con)),
post_sd_st = replace_na(if_else(is.na(post_sd_st),
post_se_st * sqrt(n_st), post_sd_st)),
post_sd_con = replace_na(if_else(is.na(post_sd_con),
post_se_con * sqrt(n_con), post_sd_con))
) %>%
# Add in pre-post correlations
mutate(
# Convert p to t (Change scores)
delta_t_value_st = replace_na(qt(delta_p_value_st/2, df=n_st-1, lower.tail=FALSE)),
delta_t_value_con = replace_na(qt(delta_p_value_con/2, df=n_con-1, lower.tail=FALSE)),
# Convert t to SE (Change scores)
delta_se_st = replace_na(if_else(is.na(delta_m_st),
(post_m_st - pre_m_st)/delta_t_value_st, delta_m_st/delta_t_value_st)),
delta_se_con = replace_na(if_else(is.na(delta_m_con),
(post_m_con - pre_m_con)/delta_t_value_con, delta_m_con/delta_t_value_con)),
# Make positive
delta_se_st = if_else(delta_se_st < 0, delta_se_st * -1, delta_se_st),
delta_se_con = if_else(delta_se_con < 0, delta_se_con * -1, delta_se_con),
# Convert SE to SD (Change scores)
delta_sd_st = replace_na(if_else(is.na(delta_sd_st),
delta_se_st * sqrt(n_st), delta_sd_st)),
delta_sd_con = replace_na(if_else(is.na(delta_sd_con),
delta_se_con * sqrt(n_con), delta_sd_con)),
# Add missing deltas
delta_m_st = replace_na(post_m_st - pre_m_st),
delta_m_con = replace_na(post_m_con - pre_m_con),
# Calculate pre-post correlation coefficient for those with pre, post, and delta SDs
ri_st = replace_na((pre_sd_st^2 + post_sd_st^2 - delta_sd_st^2)/(2 * pre_sd_st * post_sd_st)),
ri_con = replace_na((pre_sd_con^2 + post_sd_con^2 - delta_sd_con^2)/(2 * pre_sd_con * post_sd_con)),
# Remove values outside the range of -1 to +1 as they are likely due to misreporting or miscalculations in original studies
ri_st = if_else(between(ri_st,-1,1) == FALSE, NA, ri_st),
ri_con = if_else(between(ri_con,-1,1) == FALSE, NA, ri_con),
# Add 0.7 assumed correlation where missing
ri_st = replace_na(ri_st, 0.7),
ri_con = replace_na(ri_con, 0.7)
)
View(data)
targets::tar_make_future(workers = 4)
targets::tar_visnetwork()
warnings()
targets::tar_make_future(workers = 3)
remotes::install_github("paleolimbot/rbbt")
renv::install("remotes")
remotes::install_github("paleolimbot/rbbt")
remotes::install_github("paleolimbot/rbbt")
